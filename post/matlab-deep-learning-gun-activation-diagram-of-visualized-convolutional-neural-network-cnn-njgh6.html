
<!DOCTYPE html><html lang="zh-CN">

<head>
  <meta charset="utf-8">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.28.0" theme-name="Stellar" theme-version="1.28.0">
  
  <meta name="generator" content="Hexo 7.1.1">
  <meta http-equiv='x-dns-prefetch-control' content='on' />
  
  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f9fafb">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000">
  
  <title>MATLAB 深度学习丨可视化卷积神经网络CNN的激活图 - Achuan-2</title>

  
    <meta name="description" content="❓什么是CNN激活图？ 激活图就像是CNN的&quot;思维过程&quot;，展示了网络在识别图像时各个层次的关注点。简单说，它让我们窥探AI是如何&quot;看&quot;世界的！ ❓激活图具体代表什么 激活图上的每个值 (激活值) 代表了网络对该位置和对应特征的响应程度。 值越大，表示网络对该位置和特征越敏感，认为它越重要。 越深的层的激活图提取的特征越来越抽象：大多数卷积神经网络在第一个卷积层中学习检测颜色和边缘等特征。在更深的卷">
<meta property="og:type" content="article">
<meta property="og:title" content="MATLAB 深度学习丨可视化卷积神经网络CNN的激活图">
<meta property="og:url" content="http://achuan-2.top/post/matlab-deep-learning-gun-activation-diagram-of-visualized-convolutional-neural-network-cnn-njgh6.html">
<meta property="og:site_name" content="Achuan-2">
<meta property="og:description" content="❓什么是CNN激活图？ 激活图就像是CNN的&quot;思维过程&quot;，展示了网络在识别图像时各个层次的关注点。简单说，它让我们窥探AI是如何&quot;看&quot;世界的！ ❓激活图具体代表什么 激活图上的每个值 (激活值) 代表了网络对该位置和对应特征的响应程度。 值越大，表示网络对该位置和特征越敏感，认为它越重要。 越深的层的激活图提取的特征越来越抽象：大多数卷积神经网络在第一个卷积层中学习检测颜色和边缘等特征。在更深的卷">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_01-20240714171507-ibuuftc.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_02-20240714171507-3z1vzsl.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_03-20240714171507-w7zws2h.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_04-20240714171507-cw7l47s.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_05-20240714171507-m43mzo6.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_06-20240714171507-0uv1y6g.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_07-20240714171507-gufxf6t.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_08-20240714171507-2y1ip1r.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_09-20240714171507-d5tkau3.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_10-20240714171507-fzl964b.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_11-20240714171507-hu0281u.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/image-20240714170154-zwiyrsu.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/image-20240714170213-po30br1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/image-20240714165839-fwmcn0t.png">
<meta property="article:published_time" content="2024-07-14T08:25:16.000Z">
<meta property="article:modified_time" content="2024-07-22T02:36:21.000Z">
<meta property="article:author" content="Achuan-2">
<meta property="article:tag" content="Matlab">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_01-20240714171507-ibuuftc.png">
  
  
  
  <meta name="keywords" content="Matlab">

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="Achuan-2" type="application/atom+xml">
  

  <link rel="stylesheet" href="/css/main.css?v=1.28.0">

  
    <link rel="shortcut icon" href="/assets/ico/favicon.svg">
  

  

  <script src="/js/random.js"></script><link href="/css/appearence.css" rel="stylesheet"><link href="/css/tagcolor-switch.css" rel="stylesheet"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/bofeng/hyksk_webfont/dist/hyksk.css" /><link href="/css/scrollbar.css" rel="stylesheet"><link rel="preconnect" href="https://s1.hdslb.com/" /><link rel="stylesheet" href="//s1.hdslb.com/bfs/static/jinkela/long/font/regular.css" media="all" onload="this.media='all'" /><link rel="stylesheet" href="//s1.hdslb.com/bfs/static/jinkela/long/font/medium.css" media="all" onload="this.media='all'" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</head>
<body>

<div class="l_body s:aa content tech" id="start" layout="post" ><aside class="l_left"><div class="leftbar-container">


<header class="header"><div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.4/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="/assets/ico/Achuan.jpg" onerror="javascript:this.classList.add('error');this.src='https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.4/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">Achuan-2</div><div class="sub normal cap">一条没有故事的巛</div><div class="sub hover cap" style="opacity:0"> 闪闪发亮，闪闪发亮</div></a></div></header>

<div class="nav-area">
<div class="search-wrapper" id="search-wrapper"><form class="search-form"><a class="search-button" onclick="document.getElementById(&quot;search-input&quot;).focus();"><svg t="1705074644177" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1560" width="200" height="200"><path d="M1008.839137 935.96571L792.364903 719.491476a56.783488 56.783488 0 0 0-80.152866 0 358.53545 358.53545 0 1 1 100.857314-335.166073 362.840335 362.840335 0 0 1-3.689902 170.145468 51.248635 51.248635 0 1 0 99.217358 26.444296 462.057693 462.057693 0 1 0-158.255785 242.303546l185.930047 185.725053a51.248635 51.248635 0 0 0 72.568068 0 51.248635 51.248635 0 0 0 0-72.978056z" p-id="1561"></path><path d="M616.479587 615.969233a50.428657 50.428657 0 0 0-61.498362-5.534852 174.655348 174.655348 0 0 1-177.525271 3.484907 49.403684 49.403684 0 0 0-58.833433 6.76482l-3.074918 2.869923a49.403684 49.403684 0 0 0 8.609771 78.10292 277.767601 277.767601 0 0 0 286.992355-5.739847 49.403684 49.403684 0 0 0 8.404776-76.667958z" p-id="1562"></path></svg></a><input type="text" class="search-input" id="search-input" placeholder="站内搜索"></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div>


<nav class="menu dis-select"><a class="nav-item active" title="博客" href="/"><span>博客</span></a><a class="nav-item" title="友链" href="/friends/"><span>友链</span></a><a class="nav-item" title="关于" href="/about/"><span>关于</span></a></nav>
</div>
<div class="widgets">


<widget class="widget-wrapper post-list"><div class="widget-header dis-select"><span class="name">最近更新</span></div><div class="widget-body fs14"><a class="item title" href="/post/jiefang-poor-analysis-ancova-rxm1i.html"><span class="title">协方差分析 (ANCOVA)</span></a><a class="item title" href="/post/life-tips-gun-why-can-oily-pen-can-be-written-on-plastic-1ruwyi.html"><span class="title">生活窍门丨为什么油性笔可以写在塑料上</span></a><a class="item title" href="/post/anova-variance-analysis-g7i0c.html"><span class="title">ANOVA方差分析</span></a><a class="item title" href="/post/matlab-deep-learning-gun-new-coronary-pneumonia-x-ray-chest-test-based-on-resnet-z1ibtf8.html"><span class="title">Matlab 深度学习丨基于ResNet的新冠肺炎X光胸片检测</span></a><a class="item title" href="/post/immersive-translation-finally-supports-rich-text-translation-z1hrao8.html"><span class="title">沉浸式翻译终于支持富文本翻译了</span></a><a class="item title" href="/post/js-gun-mutationobserver-dom-change-observer-z1ygppd.html"><span class="title">JS丨MutationObserver（DOM 变动观察器）</span></a><a class="item title" href="/post/T%20Test.html"><span class="title">统计分析丨T检验</span></a><a class="item title" href="/post/matlab-deep-learning-gun-activation-diagram-of-visualized-convolutional-neural-network-cnn-njgh6.html"><span class="title">MATLAB 深度学习丨可视化卷积神经网络CNN的激活图</span></a><a class="item title" href="/post/matlab-deep-learning-gun-use-deep-learning-to-classify-network-camera-images-kbghh.html"><span class="title">Matlab 深度学习丨使用深度学习对网络摄像头图像进行分类</span></a><a class="item title" href="/post/why-write-a-diary-hhfd6.html"><span class="title">为什么要写日记？</span></a></div></widget>
</div>
<footer class="footer dis-select"><div class="social-wrap"><a class="social" href="https://github.com/Achuan-2/" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://api.iconify.design/icon-park/github.svg"/></a><a class="social" href="https://music.163.com/#/user/home?id=111010025" target="_blank" rel="external nofollow noopener noreferrer"><img src="https://api.iconify.design/ri:netease-cloud-music-line.svg"/></a><a class="social" href="/about/#comments" rel="noopener noreferrer"><img src="https://api.iconify.design/bx/comment-detail.svg"/></a><a class="social" href="mailto:achuan-2@outlook.com" rel="noopener noreferrer"><img src="https://api.iconify.design/clarity/email-outline-badged.svg"/></a></div></footer>
</div></aside><div class="l_main" id="main">





<div class="article banner top">
  <div class="content">
    <div class="top bread-nav footnote"><div class="left"><div class="flex-row" id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a>
<span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></div><div id="post-tag" style="margin: 5px 0px;"> <span>&nbsp标签：</span><a class="cap breadcrumb-link" href="/tags/Matlab/">Matlab</a>&nbsp</div>
<div class="flex-row" id="post-meta"><span class="text created">发布于：<time datetime="2024-07-14T08:25:16.000Z">2024-07-14 16:25</time></span><span class="sep updated"></span><span class="text updated">更新于：<time datetime="2024-07-22T02:36:21.000Z">2024-07-22 10:36</time></span></div></div></div>
    
    <div class="bottom only-title">
      
      <div class="text-area">
        <h1 class="text title"><span>MATLAB 深度学习丨可视化卷积神经网络CNN的激活图</span></h1>
        
      </div>
    </div>
    
  </div>
  </div><article class="md-text content"><h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<ul>
<li>
<p>Matlab使用<code>act1 = activations(net,im,'conv1');</code>可以查看神经网络模型中指定图生成的activation图</p>
</li>
<li>
<p><strong>激活图是什么</strong></p>
<ul>
<li><strong>由卷积层生成的特征图 (Feature Map) 经过激活函数 (Activation Function) 处理后的结果。</strong></li>
<li>激活图就像是CNN的&quot;思维过程&quot;，展示了网络在识别图像时各个层次的关注点。简单说，它让我们窥探AI是如何&quot;看&quot;世界的！</li>
</ul>
</li>
<li>
<p><strong>激活图的意义</strong></p>
<ul>
<li><strong>激活图上的每个值 (激活值) 代表了网络对该位置和对应特征的响应程度。</strong>  值越大，表示网络对该位置和特征越敏感，认为它越重要。</li>
<li><strong>越深的层的激活图提取的特征越来越抽象</strong>：大多数卷积神经网络在第一个卷积层中学习检测颜色和边缘等特征。在更深的卷积层中，网络学习检测更复杂的特征。通过可视化激活图，我们可以观察不同卷积层学习到的特征，以及这些特征如何随着网络深度的增加而变得更加抽象和高级。</li>
</ul>
</li>
</ul>
<h2 id="如何可视化卷积神经网络的激活"><a class="markdownIt-Anchor" href="#如何可视化卷积神经网络的激活"></a> 如何可视化卷积神经网络的激活</h2>
<p>此示例说明如何将图像馈送到卷积神经网络并显示网络的不同层的激活。通过将激活区域与原始图像进行比较，检查激活并发现网络学习的特征。发现较浅层中的通道学习颜色和边缘等简单特征，而较深层中的通道学习眼睛等复杂特征。以这种方式识别特征可以帮助您了解网络学习的内容。</p>
<p>该示例需要 Deep Learning Toolbox™ 和 Image Processing Toolbox™。</p>
<h3 id="加载预训练的网络和数据"><a class="markdownIt-Anchor" href="#加载预训练的网络和数据"></a> 加载预训练的网络和数据</h3>
<p>加载一个预训练的 SqueezeNet 网络。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net = squeezenet;</span><br></pre></td></tr></table></figure>
<p>读取并显示图像。保存图像大小，以便稍后使用。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">im = imread(<span class="string">&#x27;face.jpg&#x27;</span>);</span><br><span class="line">imshow(im)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_01-20240714171507-ibuuftc.png"></div></div>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imgSize = <span class="built_in">size</span>(im);</span><br><span class="line">imgSize = imgSize(<span class="number">1</span>:<span class="number">2</span>);</span><br></pre></td></tr></table></figure>
<h3 id="查看网络架构"><a class="markdownIt-Anchor" href="#查看网络架构"></a> 查看网络架构</h3>
<p>分析该网络，了解您可以查看哪些层。卷积层使用可学习的参数执行卷积。网络学习识别有用的特征，通常每个通道对应一个特征。观察到第一个卷积层有 64 个通道。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">analyzeNetwork(net)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_02-20240714171507-3z1vzsl.png"></div></div>
<p>图像输入层指定输入大小。您可以在将图像通过网络之前调整图像大小，但网络也可以处理较大的图像。如果您为网络提供较大的图像，则激活也会变大。但是，由于网络是基于大小为 227×227 的图像进行训练的，因此无法识别超过该大小的对象或特征。</p>
<h3 id="显示第一个卷积层的激活"><a class="markdownIt-Anchor" href="#显示第一个卷积层的激活"></a> 显示第一个卷积层的激活</h3>
<p>观察卷积层中的哪些区域在图像上激活，并将其与原始图像中的相应区域进行比较，以研究特征。卷积神经网络的每层由许多称为<em>通道</em>的二维数组组成。用图像对网络进行一轮训练，并检查 <code>conv1</code> 层的输出激活。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">act1 = activations(net,im,<span class="string">&#x27;conv1&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>激活以三维数组的形式返回，其中第三个维度对 <code>conv1</code> 层上的通道进行索引。要使用 <code>imtile</code> 函数显示这些激活，请将数组重构为四维。<code>imtile</code> 的输入中的第三个维度表示图像颜色。将第三个维度的大小设置为 1，因为激活没有颜色。第四个维度对通道进行索引。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sz = <span class="built_in">size</span>(act1);</span><br><span class="line">act1 = <span class="built_in">reshape</span>(act1,[sz(<span class="number">1</span>) sz(<span class="number">2</span>) <span class="number">1</span> sz(<span class="number">3</span>)]);</span><br></pre></td></tr></table></figure>
<p>现在您可以显示激活。每个激活都可能采用任何值，因此请使用 <code>mat2gray</code> 归一化输出。缩放所有激活值，以使最小激活值为 0，最大激活值为 1。在 8×8 网格上显示 64 个图像，层中的每个通道对应一个图像。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">I = imtile(mat2gray(act1),<span class="string">&#x27;GridSize&#x27;</span>,[<span class="number">8</span> <span class="number">8</span>]);</span><br><span class="line">imshow(I)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_03-20240714171507-w7zws2h.png"></div></div>
<h3 id="调查特定通道中的激活"><a class="markdownIt-Anchor" href="#调查特定通道中的激活"></a> 调查特定通道中的激活</h3>
<p>激活网格中的每个图块都是 <code>conv1</code> 层中某个通道的输出。白色像素表示强的正激活，黑色像素表示强的负激活。主要为灰色的通道未对输入图像进行强烈激活。通道激活中的像素位置对应于原始图像中的相同位置。通道中某个位置的白色像素表示该通道在该位置强激活。</p>
<p>调整通道 22 中的激活大小以使其与原始图像具有相同的大小，并显示激活。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">act1ch22 = act1(:,:,:,<span class="number">22</span>);</span><br><span class="line">act1ch22 = mat2gray(act1ch22);</span><br><span class="line">act1ch22 = imresize(act1ch22,imgSize);</span><br><span class="line"></span><br><span class="line">I = imtile(&#123;im,act1ch22&#125;);</span><br><span class="line">imshow(I)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_04-20240714171507-cw7l47s.png"></div></div>
<p>您可以看到此通道在红色像素上激活，因为通道中的偏白的像素对应于原始图像中的红色区域。</p>
<h3 id="查找最强的激活通道"><a class="markdownIt-Anchor" href="#查找最强的激活通道"></a> 查找最强的激活通道</h3>
<p>您还可以通过编程方式调查具有大量激活值的通道来尝试查找感兴趣的通道。使用 <code>max</code> 函数查找具有最多激活值的通道，调整大小并显示这些激活值。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[maxValue,maxValueIndex] = <span class="built_in">max</span>(<span class="built_in">max</span>(<span class="built_in">max</span>(act1)));</span><br><span class="line">act1chMax = act1(:,:,:,maxValueIndex);</span><br><span class="line">act1chMax = mat2gray(act1chMax);</span><br><span class="line">act1chMax = imresize(act1chMax,imgSize);</span><br><span class="line"></span><br><span class="line">I = imtile(&#123;im,act1chMax&#125;);</span><br><span class="line">imshow(I)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_05-20240714171507-m43mzo6.png"></div></div>
<p>与原始图像进行比较，注意此通道在边缘激活。它在浅色左侧/深色右侧边缘上正激活，在深色左侧/浅色右侧边缘上负激活。</p>
<h3 id="调查更深的层"><a class="markdownIt-Anchor" href="#调查更深的层"></a> 调查更深的层</h3>
<p>大多数卷积神经网络在第一个卷积层中学习检测颜色和边缘等特征。在更深的卷积层中，网络学习检测更复杂的特征。较深的层通过组合较浅层的特征来构建其特征。以调查 <code>conv1</code> 层的方式调查 <code>fire6-squeeze1x1</code> 层。计算、重构并在网格中显示激活。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">act6 = activations(net,im,<span class="string">&#x27;fire6-squeeze1x1&#x27;</span>);</span><br><span class="line">sz = <span class="built_in">size</span>(act6);</span><br><span class="line">act6 = <span class="built_in">reshape</span>(act6,[sz(<span class="number">1</span>) sz(<span class="number">2</span>) <span class="number">1</span> sz(<span class="number">3</span>)]);</span><br><span class="line"></span><br><span class="line">I = imtile(imresize(mat2gray(act6),[<span class="number">64</span> <span class="number">64</span>]),<span class="string">&#x27;GridSize&#x27;</span>,[<span class="number">6</span> <span class="number">8</span>]);</span><br><span class="line">imshow(I)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_06-20240714171507-0uv1y6g.png"></div></div>
<p>图像太多，无法详细调查，因此不妨关注一些更有趣的图像。显示 <code>fire6-squeeze1x1</code> 层中最强的激活。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[maxValue6,maxValueIndex6] = <span class="built_in">max</span>(<span class="built_in">max</span>(<span class="built_in">max</span>(act6)));</span><br><span class="line">act6chMax = act6(:,:,:,maxValueIndex6);</span><br><span class="line">imshow(imresize(mat2gray(act6chMax),imgSize))</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_07-20240714171507-gufxf6t.png"></div></div>
<p>在本例中，最大激活通道在详细特征方面不像其他一些通道那样令人感兴趣，并且表现出强力的负（深色）激活以及正（浅色）激活。此通道可能专注于面部。</p>
<p>在所有通道的网格中，可能有通道针对眼睛激活。进一步调查通道 14 和 47。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">I = imtile(imresize(mat2gray(act6(:,:,:,[<span class="number">14</span> <span class="number">47</span>])),imgSize));</span><br><span class="line">imshow(I)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_08-20240714171507-2y1ip1r.png"></div></div>
<p>许多通道包含同时存在浅色和深色的激活区域。它们分别是正激活和负激活。但是，由于 <code>fire6-squeeze1x1</code> 层后面是修正线性单元 (ReLU)，因此只使用正激活。要只调查正激活，请重复分析以可视化 <code>fire6-relu_squeeze1x1</code> 层的激活。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">act6relu = activations(net,im,<span class="string">&#x27;fire6-relu_squeeze1x1&#x27;</span>);</span><br><span class="line">sz = <span class="built_in">size</span>(act6relu);</span><br><span class="line">act6relu = <span class="built_in">reshape</span>(act6relu,[sz(<span class="number">1</span>) sz(<span class="number">2</span>) <span class="number">1</span> sz(<span class="number">3</span>)]);</span><br><span class="line"></span><br><span class="line">I = imtile(imresize(mat2gray(act6relu(:,:,:,[<span class="number">14</span> <span class="number">47</span>])),imgSize));</span><br><span class="line">imshow(I)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_09-20240714171507-d5tkau3.png"></div></div>
<p>与 <code>fire6-squeeze1x1</code> 层的激活相比，<code>fire6-relu_squeeze1x1</code> 层的激活清楚地定位到具有强面部特征的图像区域。</p>
<h3 id="测试通道是否识别眼睛"><a class="markdownIt-Anchor" href="#测试通道是否识别眼睛"></a> 测试通道是否识别眼睛</h3>
<p>检查 <code>fire6-relu_squeeze1x1</code> 层的通道 14 和 47 是否针对眼睛激活。将两眼一睁一闭的新图像输入到网络中，并将得到的激活与原始图像的激活进行比较。</p>
<p>读取并显示两眼一睁一闭的图像，并计算 <code>fire6-relu_squeeze1x1</code> 层的激活。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imClosed = imread(&#x27;face-eye-closed.jpg&#x27;);</span><br><span class="line">imshow(imClosed)</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_10-20240714171507-fzl964b.png"></div></div>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">act6Closed = activations(net,imClosed,&#x27;fire6-relu_squeeze1x1&#x27;);</span><br><span class="line">sz = size(act6Closed);</span><br><span class="line">act6Closed = reshape(act6Closed,[sz(1),sz(2),1,sz(3)]);</span><br></pre></td></tr></table></figure>
<p>在一个图窗中绘制图像和激活。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">channelsClosed = repmat(imresize(mat2gray(act6Closed(:,:,:,[14 47])),imgSize),[1 1 3]);</span><br><span class="line">channelsOpen = repmat(imresize(mat2gray(act6relu(:,:,:,[14 47])),imgSize),[1 1 3]);</span><br><span class="line">I = imtile(cat(4,im,channelsOpen*255,imClosed,channelsClosed*255));</span><br><span class="line">imshow(I)</span><br><span class="line">title(&#x27;Input Image, Channel 14, Channel 47&#x27;);</span><br></pre></td></tr></table></figure>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/VisualizeActivationsOfAConvolutionalNeuralNetworkExample_11-20240714171507-hu0281u.png"></div></div>
<p>您可以从激活中看到，通道 14 和 47 都针对单个眼睛激活，并且在某种程度上也针对嘴周围的区域激活。</p>
<p>网络从未被告知要学习眼睛的特征，但它已学习到眼睛是区分图像类的一个有用特征。以前的机器学习方法通常手动设计特定于问题的特征，但这些深度卷积网络可以为自己学习有用的特征。例如，学习识别眼睛可以帮助网络区分猎豹和豹纹地毯。</p>
<h2 id="问题和笔记"><a class="markdownIt-Anchor" href="#问题和笔记"></a> 问题和笔记</h2>
<ul>
<li>
<p>The Image Input layer specifies the input size. You can resize the image before passing it through the network, but the network also can process larger images. If you feed the network larger images, the activations also become larger. However, since the network is trained on images of size 227-by-227, it is not trained to recognize objects or features larger than that size.</p>
<ul>
<li>所以squeezenet是可以输入更大尺寸的图像的，只不过无法识别更大的物体？</li>
<li>在这个案例里没有对图像进行resize，说明是可以直接输入的</li>
</ul>
</li>
<li>
<p><strong>ReLU之后只有正activation，通过激活图来看就可以明显看出经过ReLU之后，特征会变得更加明显</strong></p>
<ul>
<li>与conv5层的激活相比，relu5层清晰地精确定位图像中具有强烈激活的面部区域特征。</li>
<li><strong>conv5层的激活图</strong></li>
</ul>
</li>
</ul>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/image-20240714170154-zwiyrsu.png"></div></div>
<ul>
<li><strong>relu5层的激活图</strong></li>
</ul>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/image-20240714170213-po30br1.png"></div></div>
<ul>
<li>
<p>参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/572124574?utm_psn=1730887377839755264">MATLAB环境下可视化卷积神经网络CNN的激活图 - 知乎 (zhihu.com)</a></p>
</li>
<li>
<p>正activation和负activation是什么？</p>
<ul>
<li>White pixels represent strong positive activations and black pixels represent strong negative activations.</li>
</ul>
</li>
</ul>
<div class="tag-plugin image"><div class="image-bg"><img src="https://raw.githubusercontent.com/Achuan-2/Picbed/pic/assets/image-20240714165839-fwmcn0t.png"></div></div>
<h2 id="资料"><a class="markdownIt-Anchor" href="#资料"></a> 资料</h2>
<ul>
<li>Matlab官方文档（squeezenet）：<a target="_blank" rel="noopener" href="https://ww2.mathworks.cn/help/deeplearning/ug/visualize-activations-of-a-convolutional-neural-network.html">https://ww2.mathworks.cn/help/deeplearning/ug/visualize-activations-of-a-convolutional-neural-network.html</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/572124574?utm_psn=1730887377839755264">MATLAB环境下可视化卷积神经网络CNN的激活图 - 知乎 (zhihu.com)</a>：用的是AlextNet来可视化激活图</li>
</ul>
<p>‍</p>

<div class="article-footer fs14">
    <section id="license">
      <div class="header"><span>许可协议</span></div>
      <div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div>
    </section>
    </div>
</article>
<div class="related-wrap" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/post/matlab-deep-learning-gun-use-deep-learning-to-classify-network-camera-images-kbghh.html">Matlab 深度学习丨使用深度学习对网络摄像头图像进行分类</a></div><div class="item" id="next"><div class="note">较早文章</div><a href="/post/why-write-a-diary-hhfd6.html">为什么要写日记？</a></div></section></div>




  <div class="related-wrap md-text" id="comments">
    <section class='header cmt-title cap theme'>
      <p>快来参与讨论吧~</p>

    </section>
    <section class='body cmt-body giscus'>
      

<svg class="loading" style="vertical-align:middle;fill:currentColor;overflow:hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="giscus" src="https://giscus.app/client.js" data-repo="Achuan-2/Achuan-2.github.io" data-repo-id="R_kgDOIT0sJw" data-category="Q&A" data-category-id="DIC_kwDOIT0sJ84CSMyl" data-mapping="pathname" data-strict="1" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous"></div>

    </section>
  </div>



<footer class="page-footer footnote"><hr><div class="sitemap"><div class="sitemap-group"><span class="fs15">博客</span><a href="/">近期</a><a href="/categories/">分类</a><a href="/tags">标签</a><a href="/archives/">归档</a></div><div class="sitemap-group"><span class="fs15">项目</span><a href="/wiki/">None</a></div><div class="sitemap-group"><span class="fs15">社交</span><a href="/friends/">友链</a><a href="/about/#comments">留言板</a></div><div class="sitemap-group"><span class="fs15">更多</span><a target="_blank" rel="noopener" href="https://github.com/Achuan-2/">GitHub</a></div></div><div class="text"><p>本站由 <a href="/">@Achuan-2</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建。<br />
本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>
<div class="main-mask" onclick="sidebar.dismiss()"></div></div><aside class="l_right">
<div class="widgets">



<widget class="widget-wrapper toc" id="data-toc" collapse="false"><div class="widget-header dis-select"><span class="name">本文目录</span><a class="cap-action" onclick="sidebar.toggleTOC()" ><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg></a></div><div class="widget-body"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text"> 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%8F%AF%E8%A7%86%E5%8C%96%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%BF%80%E6%B4%BB"><span class="toc-text"> 如何可视化卷积神经网络的激活</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E7%BD%91%E7%BB%9C%E5%92%8C%E6%95%B0%E6%8D%AE"><span class="toc-text"> 加载预训练的网络和数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-text"> 查看网络架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%BE%E7%A4%BA%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8D%B7%E7%A7%AF%E5%B1%82%E7%9A%84%E6%BF%80%E6%B4%BB"><span class="toc-text"> 显示第一个卷积层的激活</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E6%9F%A5%E7%89%B9%E5%AE%9A%E9%80%9A%E9%81%93%E4%B8%AD%E7%9A%84%E6%BF%80%E6%B4%BB"><span class="toc-text"> 调查特定通道中的激活</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E6%89%BE%E6%9C%80%E5%BC%BA%E7%9A%84%E6%BF%80%E6%B4%BB%E9%80%9A%E9%81%93"><span class="toc-text"> 查找最强的激活通道</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%83%E6%9F%A5%E6%9B%B4%E6%B7%B1%E7%9A%84%E5%B1%82"><span class="toc-text"> 调查更深的层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E9%80%9A%E9%81%93%E6%98%AF%E5%90%A6%E8%AF%86%E5%88%AB%E7%9C%BC%E7%9D%9B"><span class="toc-text"> 测试通道是否识别眼睛</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98%E5%92%8C%E7%AC%94%E8%AE%B0"><span class="toc-text"> 问题和笔记</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B5%84%E6%96%99"><span class="toc-text"> 资料</span></a></li></ol></div><div class="widget-footer">

<a class="top" onclick="util.scrollTop()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 12c0-4.714 0-7.071 1.464-8.536C4.93 2 7.286 2 12 2c4.714 0 7.071 0 8.535 1.464C22 4.93 22 7.286 22 12c0 4.714 0 7.071-1.465 8.535C19.072 22 16.714 22 12 22s-7.071 0-8.536-1.465C2 19.072 2 16.714 2 12Z"/><path stroke-linecap="round" stroke-linejoin="round" d="m9 15.5l3-3l3 3m-6-4l3-3l3 3"/></g></svg><span>回到顶部</span></a><a class="buttom" onclick="util.scrollComment()"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M10.46 1.25h3.08c1.603 0 2.86 0 3.864.095c1.023.098 1.861.3 2.6.752a5.75 5.75 0 0 1 1.899 1.899c.452.738.654 1.577.752 2.6c.095 1.004.095 2.261.095 3.865v1.067c0 1.141 0 2.036-.05 2.759c-.05.735-.153 1.347-.388 1.913a5.75 5.75 0 0 1-3.112 3.112c-.805.334-1.721.408-2.977.43a10.81 10.81 0 0 0-.929.036c-.198.022-.275.054-.32.08c-.047.028-.112.078-.224.232c-.121.166-.258.396-.476.764l-.542.916c-.773 1.307-2.69 1.307-3.464 0l-.542-.916a10.605 10.605 0 0 0-.476-.764c-.112-.154-.177-.204-.224-.232c-.045-.026-.122-.058-.32-.08c-.212-.023-.49-.03-.93-.037c-1.255-.021-2.171-.095-2.976-.429A5.75 5.75 0 0 1 1.688 16.2c-.235-.566-.338-1.178-.389-1.913c-.049-.723-.049-1.618-.049-2.76v-1.066c0-1.604 0-2.86.095-3.865c.098-1.023.3-1.862.752-2.6a5.75 5.75 0 0 1 1.899-1.899c.738-.452 1.577-.654 2.6-.752C7.6 1.25 8.857 1.25 10.461 1.25M6.739 2.839c-.914.087-1.495.253-1.959.537A4.25 4.25 0 0 0 3.376 4.78c-.284.464-.45 1.045-.537 1.96c-.088.924-.089 2.11-.089 3.761v1c0 1.175 0 2.019.046 2.685c.045.659.131 1.089.278 1.441a4.25 4.25 0 0 0 2.3 2.3c.515.214 1.173.294 2.429.316h.031c.398.007.747.013 1.037.045c.311.035.616.104.909.274c.29.17.5.395.682.645c.169.232.342.525.538.856l.559.944a.52.52 0 0 0 .882 0l.559-.944c.196-.331.37-.624.538-.856c.182-.25.392-.476.682-.645c.293-.17.598-.24.909-.274c.29-.032.639-.038 1.037-.045h.032c1.255-.022 1.913-.102 2.428-.316a4.25 4.25 0 0 0 2.3-2.3c.147-.352.233-.782.278-1.441c.046-.666.046-1.51.046-2.685v-1c0-1.651 0-2.837-.089-3.762c-.087-.914-.253-1.495-.537-1.959a4.25 4.25 0 0 0-1.403-1.403c-.464-.284-1.045-.45-1.96-.537c-.924-.088-2.11-.089-3.761-.089h-3c-1.651 0-2.837 0-3.762.089" clip-rule="evenodd"/><path fill="currentColor" d="M9 11a1 1 0 1 1-2 0a1 1 0 0 1 2 0m4 0a1 1 0 1 1-2 0a1 1 0 0 1 2 0m4 0a1 1 0 1 1-2 0a1 1 0 0 1 2 0"/></svg><span>参与讨论</span></a></div></widget>
</div></aside><div class='float-panel blur'>
  <button type='button' style='display:none' class='laptop-only rightbar-toggle mobile' onclick='sidebar.rightbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6h11m-11 6h11m-11 6h11M4 6h1v4m-1 0h2m0 8H4c0-1 2-2 2-3s-1-1.5-2-1"/></svg>
  </button>
  <button type='button' style='display:none' class='mobile-only leftbar-toggle mobile' onclick='sidebar.leftbar()'>
    <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-width="1.5"><path d="M2 11c0-3.771 0-5.657 1.172-6.828C4.343 3 6.229 3 10 3h4c3.771 0 5.657 0 6.828 1.172C22 5.343 22 7.229 22 11v2c0 3.771 0 5.657-1.172 6.828C19.657 21 17.771 21 14 21h-4c-3.771 0-5.657 0-6.828-1.172C2 18.657 2 16.771 2 13z"/><path id="sep" stroke-linecap="round" d="M5.5 10h6m-5 4h4m4.5 7V3"/></g></svg>
  </button>
</div>
</div><div class="scripts">
<script type="text/javascript">
  const ctx = {
    date_suffix: {
      just: `刚刚`,
      min: `分钟前`,
      hour: `小时前`,
      day: `天前`,
    },
    root : `/`,
  };

  // required plugins (only load if needs)
  if (`local_search`) {
    ctx.search = {};
    ctx.search.service = `local_search`;
    if (ctx.search.service == 'local_search') {
      let service_obj = Object.assign({}, `{"field":"all","path":"/search.json","content":true,"sort":"-date"}`);
      ctx.search[ctx.search.service] = service_obj;
    }
  }
  const def = {
    avatar: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.4/avatar/round/3442075.svg`,
    cover: `https://gcore.jsdelivr.net/gh/cdn-x/placeholder@1.0.4/cover/76b86c0226ffd.svg`,
  };
  const deps = {
    jquery: `https://cdn.bootcdn.net/ajax/libs/jquery/3.7.1/jquery.min.js`,
    marked: `https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js`
  }
  

</script>

<script type="text/javascript">
  const utils = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    css: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    js: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = ctx.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    jq: (fn) => {
      if (typeof jQuery === 'undefined') {
        utils.js(deps.jquery).then(fn)
      } else {
        fn()
      }
    },
    
    onLoading: (el) => {
      if (el) {
        $(el).append('<div class="loading-wrap"><svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" stroke-opacity=".3" d="M12 3C16.9706 3 21 7.02944 21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="1.3s" values="60;0"/></path><path stroke-dasharray="15" stroke-dashoffset="15" d="M12 3C16.9706 3 21 7.02944 21 12"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.3s" values="15;0"/><animateTransform attributeName="transform" dur="1.5s" repeatCount="indefinite" type="rotate" values="0 12 12;360 12 12"/></path></g></svg></div>');
      }
    },
    onLoadSuccess: (el) => {
      if (el) {
        $(el).find('.loading-wrap').remove();
      }
    },
    onLoadFailure: (el) => {
      if (el) {
        $(el).find('.loading-wrap svg').remove();
        $(el).find('.loading-wrap').append('<svg xmlns="http://www.w3.org/2000/svg" width="2em" height="2em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path stroke-dasharray="60" stroke-dashoffset="60" d="M12 3L21 20H3L12 3Z"><animate fill="freeze" attributeName="stroke-dashoffset" dur="0.5s" values="60;0"/></path><path stroke-dasharray="6" stroke-dashoffset="6" d="M12 10V14"><animate fill="freeze" attributeName="stroke-dashoffset" begin="0.6s" dur="0.2s" values="6;0"/></path></g><circle cx="12" cy="17" r="1" fill="currentColor" fill-opacity="0"><animate fill="freeze" attributeName="fill-opacity" begin="0.8s" dur="0.4s" values="0;1"/></circle></svg>');
        $(el).find('.loading-wrap').addClass('error');
      }
    },
    request: (el, url, callback, onFailure) => {
      let retryTimes = 3;
      utils.onLoading(el);
      function req() {
        return new Promise((resolve, reject) => {
          let status = 0; // 0 等待 1 完成 2 超时
          let timer = setTimeout(() => {
            if (status === 0) {
              status = 2;
              timer = null;
              reject('请求超时');
              if (retryTimes == 0) {
                onFailure();
              }
            }
          }, 5000);
          fetch(url).then(function(response) {
            if (status !== 2) {
              clearTimeout(timer);
              resolve(response);
              timer = null;
              status = 1;
            }
            if (response.ok) {
              return response.json();
            }
            throw new Error('Network response was not ok.');
          }).then(function(data) {
            retryTimes = 0;
            utils.onLoadSuccess(el);
            callback(data);
          }).catch(function(error) {
            if (retryTimes > 0) {
              retryTimes -= 1;
              setTimeout(() => {
                req();
              }, 5000);
            } else {
              utils.onLoadFailure(el);
              onFailure();
            }
          });
        });
      }
      req();
    },
  };
</script>

<script>
  const sidebar = {
    leftbar: () => {
      if (l_body) {
        l_body.toggleAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    rightbar: () => {
      if (l_body) {
        l_body.toggleAttribute('rightbar');
        l_body.removeAttribute('leftbar');
      }
    },
    dismiss: () => {
      if (l_body) {
        l_body.removeAttribute('leftbar');
        l_body.removeAttribute('rightbar');
      }
    },
    toggleTOC: () => {
      document.querySelector('#data-toc').classList.toggle('collapse');
    }
  }
</script>

<!-- required -->
<script src="/js/main.js?v=1.28.0" async></script>

<!-- optional -->

  <script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const els = document.querySelectorAll("#comments #giscus");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.error(error);
      }
      var script = document.createElement('script');
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  });
</script>




<script defer>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.services = Object.assign({}, JSON.parse(`{"mdrender":{"js":"/js/services/mdrender.js"},"siteinfo":{"js":"/js/services/siteinfo.js","api":null},"ghinfo":{"js":"/js/services/ghinfo.js"},"sites":{"js":"/js/services/sites.js"},"friends":{"js":"/js/services/friends.js"},"timeline":{"js":"/js/services/timeline.js"},"fcircle":{"js":"/js/services/fcircle.js"},"weibo":{"js":"/js/services/weibo.js"},"memos":{"js":"/js/services/memos.js"},"giscus":{"js":"/js/services/giscus_new.js"}}`));
    for (let id of Object.keys(ctx.services)) {
      const js = ctx.services[id].js;
      if (id == 'siteinfo') {
        ctx.cardlinks = document.querySelectorAll('a.link-card[cardlink]');
        if (ctx.cardlinks?.length > 0) {
          utils.js(js, { defer: true }).then(function () {
            setCardLink(ctx.cardlinks);
          });
        }
      } else {
        const els = document.getElementsByClassName(`ds-${id}`);
        if (els?.length > 0) {
          utils.jq(() => {
            if (id == 'timeline' || 'memos' || 'marked') {
              utils.js(deps.marked).then(function () {
                utils.js(js, { defer: true });
              });
            } else {
              utils.js(js, { defer: true });
            }
          });
        }
      }
    }
  });
</script>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    ctx.search = {
      path: `/search.json`,
    }
    utils.js('/js/search/local-search.js', { defer: true });
  });
</script><script>
  window.FPConfig = {
    delay: 0,
    ignoreKeywords: [],
    maxRPS: 5,
    hoverDelay: 25
  };
</script>
<script defer src="https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"></script><script>
  ctx.fancybox = {
    selector: `.swiper-slide img`,
    css: `https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css`,
    js: `https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js`
  };
  var selector = '[data-fancybox]:not(.error)';
  if (ctx.fancybox.selector) {
    selector += `, ${ctx.fancybox.selector}`
  }
  var needFancybox = document.querySelectorAll(selector).length !== 0;
  if (!needFancybox) {
    const els = document.getElementsByClassName('ds-memos');
    if (els != undefined && els.length > 0) {
      needFancybox = true;
    }
  }
  if (needFancybox) {
    utils.css(ctx.fancybox.css);
    utils.js(ctx.fancybox.js, { defer: true }).then(function () {
      Fancybox.bind(selector, {
        hideScrollbar: false,
        Thumbs: {
          autoStart: false,
        },
        caption: (fancybox, slide) => {
          return slide.triggerEl.alt || slide.triggerEl.dataset.caption || null
        }
      });
    })
  }
</script>
<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    const swiper_api = document.getElementById('swiper-api');
    if (swiper_api != undefined) {
      utils.css(`https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css`);
      utils.js(`https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js`, { defer: true }).then(function () {
        const effect = swiper_api.getAttribute('effect') || '';
        var swiper = new Swiper('.swiper#swiper-api', {
          slidesPerView: 'auto',
          spaceBetween: 8,
          centeredSlides: true,
          effect: effect,
          rewind: true,
          pagination: {
            el: '.swiper-pagination',
            clickable: true,
          },
          navigation: {
            nextEl: '.swiper-button-next',
            prevEl: '.swiper-button-prev',
          },
        });
      })
    }
  });
</script>
<link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
<script defer src="https://gcore.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
<script defer src="https://gcore.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"onload="renderMathInElement(document.body);"></script>
<script>
  document.addEventListener('DOMContentLoaded', function () {
    window.codeElements = document.querySelectorAll('.code');
    if (window.codeElements.length > 0) {
      ctx.copycode = {
        default_text: `Copy`,
        success_text: `Copied`,
        toast: `复制成功`,
      };
      utils.js('/js/plugins/copycode.js');
    }
  });
</script>


<!-- inject -->

</div></body></html>
<script>var posts=["/post/20240427-stellar-theme-update-v1280-and-decoration-zanvt4.html","/post/a-mother-s-reflection-z17orfm.html","/post/20231104-updated-win11-23h2-1xki6y.html","/post/23-years-old-zggy4y.html","post/c873b400.html","post/8b29a079.html","/post/book-recommendation-self-study-is-the-door-craft-zja4yb.html","/post/draw-calcium-imaging-hot-pictures-with-matlab-and-use-kmeans-clustering-qp7bq.html","/post/groupy-2-multi-window-management-tool-upgrade-experience-ocrer.html","/post/how-does-matlab-convert-graphics-into-outline-zo6ihg.html","/post/how-does-matlab-turn-the-image-to-uint8-z29w8nb.html","/post/how-do-you-know-what-you-took-by-automatic-vending-machine-jeapx.html","/post/how-does-matlab-give-the-rgb-image-specified-area-and-assign-the-color-in-batches-i1rsr.html","/post/how-to-give-the-roi-number-in-mask-zm8e9p.html","/post/how-to-use-abbyy-and-acrobat-to-add-bookmarks-and-directory-to-the-book-scanning-version-of-the-book-scanning-version-of-pdf-e6kup.html","/post/how-to-make-water-special-zi87c0.html","/post/i-ca-n-t-find-a-satisfactory-word-template-on-the-entire-network-so-i-made-one-myself-nano3.html","/post/js-dom-operation-1rrvs2.html","/post/i-finally-empty-the-circle-of-friends-oko3o.html","/post/is-there-a-function-like-npclip-like-npclip-limiting-the-maximum-and-minimum-value-of-the-array-1deveo.html","/post/matlab-basic-programming-grammar-1ghj9i.html","/post/matlab-2024a-everbright-functional-writing-experience-big-upgrade-eao4i.html","/post/matlab-arguments-to-return-the-function-to-the-function-2e76vf.html","/post/matlab-background-asynchronous-execution-function-z1zmis9.html","/post/matlab-control-the-gentl-protocol-high-speed-camera-z6wcf.html","/post/matlab-custom-code-supports-roller-amplification-and-drag-pictures-20eamw.html","/post/matlab-different-ctrl-mouse-right-and-mouse-right-click-1f0inv.html","/post/matlab-directly-judges-the-return-value-of-the-matrix-with-if-zqyaqj.html","/post/matlab-read-view-save-tiff-1pkevw.html","/post/matlab-reshape-scan-and-fill-in-columns-easy-to-step-on-the-pit-18flah.html","/post/matlab-superimposes-mask-a-certain-transparency-to-the-image-2seqqa.html","post/a86a49b6.html","/post/outside-the-number-glados-sign-in-baiji-is-not-easy-anymore-z2vxoy1.html","/post/python-uses-npvectorize-directional-function-to-perform-batch-processing-ipcdn.html","post/e93c4010.html","/post/scan-the-pdf-batch-with-python-batch-to-add-bookmarks-zn2z7s.html","/post/siyuan-note-use-quicker-action-to-seamlessly-link-with-zotero-zejypu.html","/post/siyuan-notes-good-partner-the-strongest-clipboard-artifact-copyq-z2grwhp.html","/post/thinking-about-waiting-power-and-order-f3swz.html","post/3bc3857.html","post/cf0a2858.html","post/f5348a5e.html","/post/what-is-the-difference-between-matlab-hello-world-vs-hello-world-single-quotation-number-and-dual-quotation-number-z1ynuyi.html","post/c873b400.html","/post/what-is-the-color-why-can-we-see-color-1v2pq4.html","/post/what-is-corporate-coroutine-python-s-async-usage-zp0b11.html","/post/why-can-convex-lens-be-used-z1cu3qk.html","/post/write-a-wechat-public-account-article-with-markdown-zatxal.html","/post/why-can-human-eyes-see-virtual-statues-z1og6up.html","/post/why-can-small-hole-imaging-be-used-and-large-holes-cannot-be-imaged-z2rx7bz.html","post/134ab329.html","post/d2b2fba7.html","post/e977bfe7.html","post/50f47788.html","post/d766b22.html","post/6e57daa8.html","post/291034.html","post/c6467c9c.html","post/595885f1.html","post/bc4b56d9.html","post/be13a22e.html","/post/immersive-translation-finally-supports-rich-text-translation-z1hrao8.html","/post/T Test.html","/post/anova-variance-analysis-g7i0c.html","/post/life-tips-gun-why-can-oily-pen-can-be-written-on-plastic-1ruwyi.html","/post/js-gun-mutationobserver-dom-change-observer-z1ygppd.html","/post/matlab-deep-learning-gun-activation-diagram-of-visualized-convolutional-neural-network-cnn-njgh6.html","/post/jiefang-poor-analysis-ancova-rxm1i.html","/post/matlab-deep-learning-gun-new-coronary-pneumonia-x-ray-chest-test-based-on-resnet-z1ibtf8.html","/post/matlab-deep-learning-gun-use-deep-learning-to-classify-network-camera-images-kbghh.html","/post/matlab-optimization-abnormal-processing-fprintf-s-wonderful-use-z2wefdb.html","/post/my-note-management-method-in-onenote-wolai-zrqwln.html","/post/think-about-how-i-should-spend-my-day-zl38tl.html","/post/moc-manage-the-notes-link-to-the-theme-4uatt.html","/post/why-write-a-diary-hhfd6.html"];function toRandomPost(){ var randomPath = posts[Math.floor(Math.random()*posts.length)]; var encodedPath = encodeURIComponent(randomPath); window.open('/' + encodedPath, "_self"); };</script>